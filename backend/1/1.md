# Backend Communication Design patterns

## Request - Response Model

- Client sends a Request
- Server parses the Request
- Server processes the Request
- Server sends a Response
- Client parses the Response and consume it

### Where it is used?

- Web, HTTP, DNS, SSH
- RPC (remote procedure call)
- SQL and Database Protocols
- APIs (REST/SOAP/GraphQL)

### Anatomy of a Request / Response

- A request structure is defined by both client and server
- Request has a boundary
- Defined by a protocol and message format

```
GET / HTTP/1.1
Headers
<CRLF>
BODY
```

### Where it doesn't work

- [Notification service]
- [Chatting application]
- [Very Long requests]
- [What if clinet disconnects?]

## Synchronous vs Asynchronous

> can I do work while I'm waiting?

### Synchronous I/O

- Caller sends a request and blocks [(]until response[)]
- Caller cannot execute any code meanwhile
- Receiver responds, Caller unblocks
- Caller and Receiver are in "[sync]"

### Asynchronous I/O

- Caller sends a request
- Caller can work until it gets a response
- Caller either:
  - Checks if the response is ready([epoll])
  - Receiver calls back when it's done([io_uring])
  - Spins up a new thread that blocks

### Synchronous vs Asynchronous in Request Response

- Synchronicity is a client property
- most modern client libraries are asynchronous

## Push

> I want it as soon as possible

### Request/Response isn't always ideal

- Client wants real time notification from backend
  - A user just logged in
  - A message is just received
- Push model is good for certain cases

### What is Push?

- Client connects to a server
- Server sends data to the client
- Client doesn't have to request anything
- Protocol must be bidirectional
- Used by RabbitMQ

### Push Pros and Cons

- Pros✅
  - Real Time
- Cons❌
  - Clients must be online
  - Client might not be able to handle
  - Requires a bidirectional protocol
  - Polling is preferred for light clients

## Short Polling

> Request is taking a while, I'll check with you later

### Where request/response isn't ideal

- A request takes long time to process
  - Upload a youtube video
- The backend want to sends notification
  - A user just logged in

### What is Short Polling?

- Client sends a request
- Server responds immediately with a handle
- Server continues to process the request
- Client uses that handle to check for status
- Multiple "short" request response as polls

```
--request-->
<--RequestID X--
--Is X ready?-->
<--No--
--Is X ready?-->
<--No--
--Is X ready?-->
<--Response(yes it is ready and here is the response)--

```

### Short Polling Pros and Cons

- Pros✅
  - Simple
  - Good for long running requests
  - Client can disconnect safely
- Cons❌
  - Too chatty
  - Network bandwidth
  - Wasted Backend resources

## Long Polling

> Request is taking long, I'll check with you later [But talk to me only when it's ready]

### Where request/response & polling isn't ideal

- A request takes long time to process
  - Upload a youtube video
- The backend want to sends notification
  - A user just logged in
- Short Polling is a good but cahtty
- Meet Long polling (Kafka uses it)

### What is Long Polling?

- Client sends a request
- Server responds immediately with a handle
- Server continues to process the request
- Client uses that handle to check for status
- Server DOES not reply until it has the response
- SO we got a handle, we can disconnect and we are less chatty
- Some variation has timeouts too

### Long Polling Pros and Cons

- Pros✅
  - Less chatty and backend friendly
  - Client can still disconnect
- Cons❌
  - Not real time

## Server Sent Events

> One Request, a very very long response

### Limitation of Request/Response

- Vanilla Reuqest/Response isn't ideal for notification backend
- Client wants real time notification from backend
  - A user just logged in
  - A message is just received
- Push works but restrictive
- Server Sent Events works with Request/Response and also HTTP
- Designed for HTTP

### What is Server Sent Events?

- A response has start and end
- Client sends a request
- Server sends logical events as part of response
- Server never writes the end of the response
- It is still a request but an unending response
- Client parses the streams data looking for this events(logging is, message, ...)

### Server Sent Events Pros and Cons

- Pros✅
  - Real time
  - Compatible with Request/Response
- Cons❌
  - Client must be online
  - Client might not be able to handle
  - Polling is preferred for light clients
  - HTTP/1.1 problem(6 connections)

## Publish Subscribe

> One Publisher many readers

### Pub/Sub pros and cons

- Pros✅
  - Scales with multiple receivers
  - Great for microservices
  - Loose Coupling
  - Works while clients not running
- Cons❌
  - Message delivery issues
  - Complexity
  - Network saturation

## Multiplexing vs Demultiplexing

> HTTP/2, QUIC, Connection Pool, MPTCP

[multiplexing] -> merge several connection into one connection
[demultiplexing] -> expand a connection into several connection

### Connection Pooling

> Connection pooling is a technique used in database management to improve the efficiency of handling multiple requests by maintaining a set of pre-established connections to a database server. Instead of creating a new database connection for each request, which can be resource-intensive and slow, a connection pool reuses existing connections from the pool. This approach reduces the overhead associated with establishing and tearing down connections, leading to improved performance and scalability.

❕Connection pooling can also be implemented at the middleware level, where each request is processed using a connection from the pool before being released back for reuse.

**[📝NOTE]**
[in HTTP/1.1] Chrome allows up to 6 connection per domain, user's requests are demultiplexing in the 6 connections.

## Stateless vs Stateful

> Is state stored in the backend?

### Stateful vs Stateless backend

- Stateful
  - Stores state about clients in its memory
  - Depends on the information being there
- Stateless
  - Client is responsible to **transfer the state** with every request
  - May store but can safely lose it

### Stateless Backends

> A stateless application does not retain any information about past interactions or sessions between the client and server. Each request from a client is independent of previous requests and must contain all necessary information required to complete its processing. This architecture simplifies scalability, fault tolerance, and horizontal scaling.

- **No Session Data:** The server does not store any session-specific data in memory or persistent storage.
- **Idempotent Requests:** Each request can be processed independently, without affecting the outcome of other requests. This makes it easier to handle retries and load balancing.
- **Scalability:** Easily scalable by adding more servers, as each server processes requests independently without relying on shared state.
- **Fault Tolerance:** Servers can fail or restart without impacting ongoing sessions since there is no session-specific data stored.

- Stateless backends can still store date somewhere else
- Can you restart the backend during idle time while the client workflow continues to work?

#### What makes a backend stateless?

- Stateless backends can store state somewhere else (database)
- The backend remain stateless but the system is stateful
- Can you restart the backend during idle time while the client workflow continue to work?

**Key Points:**

- **Authentication:** Typically handled through tokens (e.g., JWT) included in each request.
- **No Session Storage:** Avoid using server-side sessions or cookies that store user state.

### Stateful Backends

> A stateful application maintains session-specific data on the server side, keeping track of past interactions between clients and servers. This architecture requires more complex management of sessions, making it less scalable but suitable for applications that need to retain context across multiple requests.

- **Session Data:** The server stores information about the user's session (e.g., authentication status, preferences) in memory or persistent storage.
- **State Dependency:** Requests depend on previous interactions; the state of a session affects how future requests are processed.
- **Complexity:** More challenging to scale horizontally because servers must share and synchronize session data.
- **Limited Scalability:** Requires more resources and coordination for load balancing compared to stateless architectures.

### 🔧Stateless and Stateful Protocols

- The protocols can be designed to store state
- TCP is stateful
  - Sequences, Connection file descriptor
- UDP is stateless
  - DNS send queryID in UDP to identify queries
  - QUIC sends connectionID to identify connection
- You can build a stateless protocol on top of a stateful one and vise versa
  - HTTP([stateless]) on top or TCP([stateful])
  - if TCP breaks, HTTP blindly create another one
  - QUIC([stateful]) on top of UDP([stateless])

### Complete Stateless System

- Stateless Systems are rare
- State is carried with every request
- A backend service that relies completely on the input
  - Check if input param is a prime number
- JWT (JSON Web Token)

## Sidecar Pattern

> Thick clients, Thicket backends

**Key Characteristics of the Sidecar Pattern:**

1. **Separation of Concerns:** By running as separate processes within the same container, sidecars allow for distinct responsibilities to be managed independently. This separation helps maintain clean codebases and reduces inter-service dependencies.

2. **Extensibility:** Sidecars can add features such as logging, monitoring, security, configuration management, or service mesh capabilities without altering the core functionality of the main application.

3. **Scalability:** Since sidecars are part of the same deployment unit as the main service, they scale horizontally alongside the primary application, ensuring consistent resource allocation and performance.

4. **Isolation:** Sidecars provide a layer of isolation between services and their enhancements, reducing the risk of cascading failures and improving fault tolerance.

5. **Modularity:** The architecture allows for easy swapping or updating of sidecar components without impacting the main service, facilitating continuous integration and deployment (CI/CD) processes.

**Sidecar Examples**

- service mesh proxies
  - Linkerd, Istio, Envoy
- Sidecar Proxy Container
- Must be Layer 7 Proxy

### Pros and Cons

- Pros✅

  - Language agnostic(polyglot)
  - Protocol upgrade
  - Security
  - Tracing and Monitoring
  - Service Discovery
  - Caching

- Cons❌
  - Complexity
  - Latency
